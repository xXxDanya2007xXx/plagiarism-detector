# Методы сравнения и интерпретация результата

Проект вычисляет **схожесть текста** между работами и помогает найти пары для ручной проверки.
Схожесть ≠ доказательство плагиата.

## Конвейер обработки

1. Чтение документов из папки (`.txt/.pdf/.docx`).
2. Нормализация и токенизация.
3. Расчёт матрицы схожести.
4. Генерация отчётов (JSON/Markdown/PNG) и статической страницы (HTML).

## Метрики

### TF‑IDF cosine similarity
Строится TF‑IDF представление документов (по токенам) и считается косинусная близость.

### SequenceMatcher ratio
Метрика на основе `difflib.SequenceMatcher`. Хорошо ловит большие общие фрагменты.

### N‑gram Jaccard similarity
Из токенов строятся n‑граммы и считается:
`J(A,B) = |A ∩ B| / |A ∪ B|`.

### LCS similarity
Считается LCS (longest common subsequence) по токенам и нормализуется:
`2*LCS(a,b)/(len(a)+len(b))`.

## Итоговый скор

Итоговый скор — взвешенная комбинация сигналов (веса и параметры сохраняются в `report.json -> config`).
Это сделано для воспроизводимости: видно, какие параметры использовались при генерации отчёта.

## Интерпретация результата

- `top_pairs` — пары, которые **превысили порог** `threshold`
- `top_pairs_overall` — самые похожие пары **в целом**, даже если порог не пройден
- `summary` — агрегаты по всем попарным сравнениям (max/mean/median, количество пар ≥ threshold)

## Ограничения

- Общие шаблоны, формулировка задания и корректные цитаты увеличивают схожесть.
- Для коротких работ результаты менее стабильны.
- Это инструмент для скрининга: пары нужно проверять вручную.
