# Методы сравнения и интерпретация результата

Этот проект вычисляет **схожесть текста** между работами и помогает найти пары для ручной проверки.
Схожесть ≠ доказательство плагиата.

## Конвейер обработки

1. Чтение файлов из папки (сейчас `.txt`).
2. Нормализация и токенизация текста.
3. Расчёт попарной матрицы схожести.
4. Формирование отчётов: JSON, Markdown и heatmap (PNG).

## Метрики схожести

Набор метрик может расширяться; актуальный список смотрите в коде и в `report.json` (блок `config`).

### TF‑IDF + cosine similarity
Строится TF‑IDF представление документов, затем считается косинусная близость.
- Хороший базовый метод для “лексической” похожести
- Относительно устойчив к шуму

### SequenceMatcher ratio
Метрика на основе `difflib.SequenceMatcher`.
- Хорошо ловит почти прямое копирование и большие общие фрагменты
- Чувствительна к перестановкам

### N‑gram Jaccard similarity
Из токенов строятся n‑граммы (например, триграммы слов) и считается:
`J(A,B) = |A ∩ B| / |A ∪ B|`
- Помогает ловить частичное копирование и совпадающие формулировки

## Итоговый скор

Итоговый скор обычно представляет собой взвешенную комбинацию отдельных сигналов.
Веса и параметры фиксируются в отчёте (`report.json -> config`), чтобы воспроизводимость была прозрачной.

## Порог подозрительности

- По умолчанию: `0.75`
- Повышайте порог, если слишком много ложных совпадений.
- Понижайте порог, если хотите ловить больше потенциально подозрительных случаев (но придётся больше смотреть вручную).

## Ограничения

- Шаблонные задания, общие вводные фразы и корректные цитаты повышают схожесть.
- Для коротких работ метрики менее стабильны.
- Схожесть текста не учитывает “смысловую перефразировку” на уровне семантики (если не добавлять специальные модели).
